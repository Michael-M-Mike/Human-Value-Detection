{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4eb0358080fe4941ab6d2602108507f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7658d5bd04444fca92e6167a1bd20ab8",
              "IPY_MODEL_43d23713ecaa4365a4d6be6c08e7eb7b",
              "IPY_MODEL_efa2936587ee4737968e2b520cd1b9fd"
            ],
            "layout": "IPY_MODEL_16a9d807d0724596a0c98a6a9776dac8"
          }
        },
        "7658d5bd04444fca92e6167a1bd20ab8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fb233634dea42d398898f16f0f7ab10",
            "placeholder": "​",
            "style": "IPY_MODEL_e7be07c33cc54614b94707c6573b0591",
            "value": "Map: 100%"
          }
        },
        "43d23713ecaa4365a4d6be6c08e7eb7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ff1b4f8e254471d92084ae7e0a687eb",
            "max": 1896,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f38ae62a8a1e467fa583ecdf4a76e039",
            "value": 1896
          }
        },
        "efa2936587ee4737968e2b520cd1b9fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4c1d5e54b984c908929fc0a05023e8b",
            "placeholder": "​",
            "style": "IPY_MODEL_ac72cf349337415bb5ea00a97b3311c0",
            "value": " 1896/1896 [00:00&lt;00:00, 6418.30 examples/s]"
          }
        },
        "16a9d807d0724596a0c98a6a9776dac8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fb233634dea42d398898f16f0f7ab10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7be07c33cc54614b94707c6573b0591": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ff1b4f8e254471d92084ae7e0a687eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f38ae62a8a1e467fa583ecdf4a76e039": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e4c1d5e54b984c908929fc0a05023e8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac72cf349337415bb5ea00a97b3311c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbeNjlgAIlYh"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "Artificial Intelligence Master's Degree (2022 - 2023)\n",
        "\n",
        "Natural Language Processing\n",
        "\n",
        "# **Stance Classification for Human Value Premises**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sso0lMlLIuWa"
      },
      "source": [
        "---\n",
        "---\n",
        "## Abstract\n",
        "\n",
        "The notebook finetunes `distilRoBERTa-base` model on the task of classifying the stance of an argument premise with its conclusion. For example:\n",
        "```\n",
        "Input:\n",
        "Premise: affirmative action helps with employment equity.\n",
        "Conclusion: We should end affirmative action\n",
        "\n",
        "Prediction: against\n",
        "Truth: against\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEplxkDaQGY9"
      },
      "source": [
        "---\n",
        "---\n",
        "## Table of Contents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "toc",
        "id": "zLyAG_cKQSqH"
      },
      "source": [
        ">[Stance Classification for Human Value Premises](#folderId=1WhJ0uu3eFDQmelokM4Dk1B7KXrF9_mn_&updateTitle=true&scrollTo=HbeNjlgAIlYh)\n",
        "\n",
        ">>[Abstract](#folderId=1WhJ0uu3eFDQmelokM4Dk1B7KXrF9_mn_&updateTitle=true&scrollTo=Sso0lMlLIuWa)\n",
        "\n",
        ">>[Table of Contents](#folderId=1WhJ0uu3eFDQmelokM4Dk1B7KXrF9_mn_&updateTitle=true&scrollTo=UEplxkDaQGY9)\n",
        "\n",
        ">>[Background](#folderId=1WhJ0uu3eFDQmelokM4Dk1B7KXrF9_mn_&updateTitle=true&scrollTo=yCz0ldhNI6mB)\n",
        "\n",
        ">>[Implementation](#folderId=1WhJ0uu3eFDQmelokM4Dk1B7KXrF9_mn_&updateTitle=true&scrollTo=UwGofHSFI8y5)\n",
        "\n",
        ">>>[Setup](#folderId=1WhJ0uu3eFDQmelokM4Dk1B7KXrF9_mn_&updateTitle=true&scrollTo=P3IBzZViI_kS)\n",
        "\n",
        ">>>[Imports](#folderId=1WhJ0uu3eFDQmelokM4Dk1B7KXrF9_mn_&updateTitle=true&scrollTo=UghrvFDbTfLQ)\n",
        "\n",
        ">>>[Dataset: Loading](#folderId=1WhJ0uu3eFDQmelokM4Dk1B7KXrF9_mn_&updateTitle=true&scrollTo=B10X0u6MJCFY)\n",
        "\n",
        ">>>[Dataset: Preprocessing](#folderId=1WhJ0uu3eFDQmelokM4Dk1B7KXrF9_mn_&updateTitle=true&scrollTo=rUSnQIQGUGch)\n",
        "\n",
        ">>>[Dataset: Tokenization](#folderId=1WhJ0uu3eFDQmelokM4Dk1B7KXrF9_mn_&updateTitle=true&scrollTo=JeB6VKP_VcZt)\n",
        "\n",
        ">>>[Model: Creation](#folderId=1WhJ0uu3eFDQmelokM4Dk1B7KXrF9_mn_&updateTitle=true&scrollTo=Y5aTQgCWJV3K)\n",
        "\n",
        ">>>[Model: Fine-Tuning](#folderId=1WhJ0uu3eFDQmelokM4Dk1B7KXrF9_mn_&updateTitle=true&scrollTo=XNdQyQZ4XIUS)\n",
        "\n",
        ">>>[Inference](#folderId=1WhJ0uu3eFDQmelokM4Dk1B7KXrF9_mn_&updateTitle=true&scrollTo=Wrhn4wITbIl9)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwGofHSFI8y5"
      },
      "source": [
        "---\n",
        "---\n",
        "## Implementation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3IBzZViI_kS"
      },
      "source": [
        "### Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers[torch] datasets evaluate"
      ],
      "metadata": {
        "id": "0t_AyEP6Tf1x"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "UghrvFDbTfLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ArAziATi5XDJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Machine Learning\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, f1_score"
      ],
      "metadata": {
        "id": "s2kfgHteF_b3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hugging Face\n",
        "import evaluate\n",
        "from datasets import Dataset, DatasetDict, load_dataset, concatenate_datasets\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from transformers import DataCollatorWithPadding, pipeline"
      ],
      "metadata": {
        "id": "mcynmt1l1ktz"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "V8pclkxLT1T2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Machine Learning\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, f1_score"
      ],
      "metadata": {
        "id": "Ll8IQBz1T1T3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hugging Face\n",
        "from datasets import Dataset, DatasetDict, load_dataset, concatenate_datasets\n",
        "from transformers import AutoConfig, AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, EvalPrediction"
      ],
      "metadata": {
        "id": "TZiJXWyGT1T3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset: Loading"
      ],
      "metadata": {
        "id": "B10X0u6MJCFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset from HF\n",
        "dataset = load_dataset(\"webis/Touche23-ValueEval\")"
      ],
      "metadata": {
        "id": "7MVySyOX1Wfg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_bp3t78w9L-",
        "outputId": "73419083-f6d8-45af-8061-303ee7fc8424"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['Argument ID', 'Conclusion', 'Stance', 'Premise', 'Labels'],\n",
              "        num_rows: 5393\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['Argument ID', 'Conclusion', 'Stance', 'Premise', 'Labels'],\n",
              "        num_rows: 1896\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['Argument ID', 'Conclusion', 'Stance', 'Premise', 'Labels'],\n",
              "        num_rows: 1576\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset: Preprocessing"
      ],
      "metadata": {
        "id": "rUSnQIQGUGch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_dataset(dataset_dict):\n",
        "    \"\"\"\n",
        "        1. Concatenate the \"premise\" and \"conclusion\" in a single \"text\" field.\n",
        "        2. Binarize the \"stance\" into the \"label\" field.\n",
        "    \"\"\"\n",
        "    def encode_stance(stance):\n",
        "        return 1 if stance == \"in favor of\" else 0\n",
        "\n",
        "    def preprocess_stance(example):\n",
        "        premise = example[\"Premise\"]\n",
        "        conclusion = example[\"Conclusion\"]\n",
        "        example[\"text\"] = f\"Premise: {premise}\\nConclusion: {conclusion}\"\n",
        "        example[\"label\"] = encode_stance(example[\"Stance\"])\n",
        "\n",
        "        return example\n",
        "\n",
        "    # Use the .map function to apply the preprocessing to the \"Stance\" field\n",
        "    modified_dataset_dict = dataset_dict.map(preprocess_stance, remove_columns=[\"Argument ID\", \"Conclusion\", \"Stance\", \"Labels\", \"Premise\"])\n",
        "\n",
        "    return modified_dataset_dict\n",
        "\n",
        "ds = preprocess_dataset(dataset)"
      ],
      "metadata": {
        "id": "PpBjuzbiURnf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bNsGLpjVLXV",
        "outputId": "2ae6e1cf-bd0c-4695-9d2c-cec2fa665d31"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 5393\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 1896\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 1576\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset: Tokenization"
      ],
      "metadata": {
        "id": "JeB6VKP_VcZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model name and tokenizer\n",
        "model_name = \"distilroberta-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "AHixLXn9VxEO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_batch(batch):\n",
        "    inputs = tokenizer(batch[\"text\"], truncation=True)\n",
        "    inputs[\"label\"] = batch[\"label\"]\n",
        "\n",
        "    return inputs\n",
        "\n",
        "# Use the .map function to tokenize the dataset\n",
        "ds_tokenized = ds.map(tokenize_batch, batched=True, remove_columns=ds[\"train\"].column_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "4eb0358080fe4941ab6d2602108507f3",
            "7658d5bd04444fca92e6167a1bd20ab8",
            "43d23713ecaa4365a4d6be6c08e7eb7b",
            "efa2936587ee4737968e2b520cd1b9fd",
            "16a9d807d0724596a0c98a6a9776dac8",
            "8fb233634dea42d398898f16f0f7ab10",
            "e7be07c33cc54614b94707c6573b0591",
            "7ff1b4f8e254471d92084ae7e0a687eb",
            "f38ae62a8a1e467fa583ecdf4a76e039",
            "e4c1d5e54b984c908929fc0a05023e8b",
            "ac72cf349337415bb5ea00a97b3311c0"
          ]
        },
        "id": "hibOo6mIVWNW",
        "outputId": "d00e05fb-48df-40a1-d574-0fc61afad5cb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1896 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4eb0358080fe4941ab6d2602108507f3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds_tokenized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6C1YgTbHWKlO",
        "outputId": "0072c8c8-eee0-4bed-8f24-1d5d2647431b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['label', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 5393\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['label', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 1896\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['label', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 1576\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model: Creation"
      ],
      "metadata": {
        "id": "Y5aTQgCWJV3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the id2label and label2id lists\n",
        "id2label = {0: \"against\", 1: \"in favor of\"}\n",
        "label2id = {\"against\": 0, \"in favor of\": 1}"
      ],
      "metadata": {
        "id": "FWf93GIsWg3E"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=2,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        "    )"
      ],
      "metadata": {
        "id": "eEMOwPcCtVNV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a0c3b4e-367b-4bbe-95de-328266a6d556"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model: Fine-Tuning"
      ],
      "metadata": {
        "id": "XNdQyQZ4XIUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the accuracy metric\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "WUbo9IimWZi-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"stance_classifier\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=concatenate_datasets([ds_tokenized[\"train\"], ds_tokenized[\"validation\"]]),\n",
        "    eval_dataset=ds_tokenized[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "Fsn080xfXfS9",
        "outputId": "056beb1b-0588-4b64-8eb0-9daa5ebb8560"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='684' max='684' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [684/684 03:33, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.378478</td>\n",
              "      <td>0.838198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.334427</td>\n",
              "      <td>0.862944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.393500</td>\n",
              "      <td>0.361465</td>\n",
              "      <td>0.860406</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=684, training_loss=0.34359357510393823, metrics={'train_runtime': 214.6473, 'train_samples_per_second': 101.874, 'train_steps_per_second': 3.187, 'total_flos': 547451019640152.0, 'train_loss': 0.34359357510393823, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference"
      ],
      "metadata": {
        "id": "Wrhn4wITbIl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_text(texts):\n",
        "\n",
        "    label_list = [\"against\", \"in favor of\"]\n",
        "    device = \"cuda\"\n",
        "\n",
        "    # Tokenize input texts as a batch\n",
        "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=128, is_split_into_words=False)\n",
        "\n",
        "    # Move inputs to the same device as the model\n",
        "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
        "\n",
        "    # Perform inference\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Get predicted probabilities for each class\n",
        "    logits = outputs.logits\n",
        "    probabilities = torch.softmax(logits, dim=1).tolist()\n",
        "\n",
        "    # Create a list of dictionaries mapping class labels to their corresponding probabilities for each input\n",
        "    results = [{label: prob for label, prob in zip(label_list, probs)} for probs in probabilities]\n",
        "\n",
        "    # Get the predicted labels with the highest probabilities for each input\n",
        "    predicted_labels = [max(result, key=result.get) for result in results]\n",
        "\n",
        "    return predicted_labels"
      ],
      "metadata": {
        "id": "q7aC7yiLsMK9"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = dataset[\"test\"][\"Stance\"]\n",
        "y_pred = classify_text(ds[\"test\"][\"text\"])"
      ],
      "metadata": {
        "id": "b5bbfUp5xguD"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = ds[\"test\"][\"text\"][0]\n",
        "print(f\"Input:\\n{example}\\n\")\n",
        "\n",
        "print(f\"Prediction: {y_pred[0]}\")\n",
        "print(f\"Truth: {y_true[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtCjE6aku05o",
        "outputId": "c1265c6b-7136-4892-9343-58a374845fd0"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            "Premise: affirmative action helps with employment equity.\n",
            "Conclusion: We should end affirmative action\n",
            "\n",
            "Prediction: against\n",
            "Truth: against\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w2JXSxZsvPoy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}